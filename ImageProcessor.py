import cv2
from PIL import Image, ImageDraw
import os
import numpy as np
from pdf2image import convert_from_path

class ImageProcessor:
    @staticmethod
    def find_checkboxes(image, process_code=None, model=None, dept=None):
        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
        blurred = cv2.GaussianBlur(gray, (3, 3), 0)
        edges = cv2.Canny(blurred, 50, 150)
        contours, _ = cv2.findContours(edges, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)
        
        boxes = []
        for cnt in contours:
            approx = cv2.approxPolyDP(cnt, 0.04 * cv2.arcLength(cnt, True), True)
            if len(approx) == 4:
                x, y, w, h = cv2.boundingRect(approx)
                aspect_ratio = float(w) / h
                if 0.9 <= aspect_ratio <= 1.13:  # ì •ì‚¬ê°í˜•ì— ê°€ê¹Œìš´ ë¹„ìœ¨
                    # ì‘ì€ ì‚¬ê°í˜•ë§Œ ì„ íƒ (ì˜ˆ: 10x10 ~ 30x30 í”½ì…€)
                    if 7 <= w <= 25 and 7 <= h <= 25:
                        # ë‹¨ìì²´ê²°ê¸° ê³µì •(06)ì¼ ê²½ìš° ì œì™¸ ì˜ì—­ ì²´í¬
                        if dept in ['3165', 'UTA']:
                            if process_code == '06' and dept in ['3165', 'UTA']:
                                # ì œì™¸ ì˜ì—­ì— ìˆëŠ” ì²´í¬ë°•ìŠ¤ëŠ” ê±´ë„ˆëœ€
                                if 800 <= x <= image.shape[1] and 200 <= y <= 380:
                                    continue
                            elif process_code == '11' and dept in ['3165', 'UTA']:
                                if 825 <= x <= image.shape[1] and 180 <= y <= 350:
                                    continue
                            elif process_code == '15' and dept in ['3165', 'UTA']:
                                if 850 <= x <= image.shape[1] and 180 <= y <= 310:
                                    continue
                        if dept in ['3186', 'JUXTA']:
                            if process_code == '10' and model == 'VJ77':
                                if 550 <= x <= image.shape[1] and 270 <= y <= 380:
                                    continue
                            elif process_code == '11' and model == 'VJ77':
                                if 0 <= x <= image.shape[1] and 0 <= y <= 500:
                                    continue
                            elif process_code == '11' and model == 'VJ77':
                                if 0 <= x <= image.shape[1] and 0 <= y <= 500:
                                    continue
                            elif process_code == '11' and model != 'VJ77':
                                if 0 <= x <= 50 and 0 <= y <= image.shape[0]:
                                    continue
                            elif process_code == '07' and model != 'VJ77':
                                if 0 <= x <= image.shape[1] and 400 <= y <= 510:
                                    continue
                            elif process_code == '10' and model != 'VJ77':
                                if 0 <= x <= 700 and 80 <= y <= 140:
                                    continue
                    
                        # ë‚´ë¶€ ì˜ì—­ì˜ ê· ì¼ì„± ê²€ì‚¬
                        mask = np.zeros(gray.shape, np.uint8)
                        cv2.drawContours(mask, [cnt], 0, 255, -1)
                        mean, stddev = cv2.meanStdDev(gray, mask=mask)
                        
                        # ê· ì¼ì„±ì´ ë†’ì€ ê²½ìš°ë§Œ ì„ íƒ
                        if stddev[0][0] < 40:
                            boxes.append({'x': x, 'y': y, 'width': w, 'height': h})
                            #print(f"ì²´í¬ë°•ìŠ¤ ë°œê²¬: ({x}, {y}), í¬ê¸°: {w}x{h}, ê· ì¼ì„±: {stddev[0][0]:.2f}, {image.shape[1]},{image.shape[0]},{process_code},{model}")
        
        result_image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
        draw = ImageDraw.Draw(result_image)
        for box in boxes:
            draw.rectangle([box['x'], box['y'], box['x'] + box['width'], box['y'] + box['height']], outline='red')
        return result_image, boxes

    @staticmethod
    def debug_clustering(image_path, threshold_ratio=0.35, proximity_distance=10):
        """ë°€ì§‘ êµ¬ê°„ ë¶„ì„ ë””ë²„ê¹…"""
        img = cv2.imread(image_path)
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        _, binary = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY_INV)

        horizontal_projection = np.sum(binary, axis=1)
        row_threshold = img.shape[1] * 255 * threshold_ratio
        detected_lines = np.where(horizontal_projection > row_threshold)[0]

        print("="*60)
        print("ğŸ” ë°€ì§‘ êµ¬ê°„ ë¶„ì„")
        print("="*60)
        print(f"íƒì§€ëœ í–‰ë“¤: {detected_lines}")
        print(f"ê·¼ì ‘ ê±°ë¦¬ ê¸°ì¤€: {proximity_distance}px")

        # ê·¸ë£¹í™” ê³¼ì • ìƒì„¸ ì¶”ì 
        groups = []
        current_group = [detected_lines[0]]

        for i in range(1, len(detected_lines)):
            distance = detected_lines[i] - detected_lines[i-1]
            if distance <= proximity_distance:
                current_group.append(detected_lines[i])
                print(f"  Row {detected_lines[i]} â†’ ê·¸ë£¹ì— ì¶”ê°€ (ê±°ë¦¬: {distance}px)")
            else:
                groups.append(current_group)
                print(f"  ê·¸ë£¹ ì™„ì„±: {current_group[0]}~{current_group[-1]} (í¬ê¸°: {len(current_group)})")
                current_group = [detected_lines[i]]
                print(f"  Row {detected_lines[i]} â†’ ìƒˆ ê·¸ë£¹ ì‹œì‘ (ê±°ë¦¬: {distance}px)")
        
        groups.append(current_group)
        print(f"  ë§ˆì§€ë§‰ ê·¸ë£¹: {current_group[0]}~{current_group[-1]} (í¬ê¸°: {len(current_group)})")

        print(f"\nğŸ“Š ìµœì¢… ê·¸ë£¹ ë¶„ì„:")
        for i, group in enumerate(groups):
            front_row = min(group)
            back_row = max(group)
            print(f"  ê·¸ë£¹ {i+1}: Row {front_row}~{back_row} â†’ ë¶„í• ì : {front_row}")

        return groups


    @staticmethod
    def debug_horizontal_projection(image_path, threshold_ratio=0.4):
        """ê° í–‰ì˜ í”½ì…€ í•©ê³„ë¥¼ ê·¸ë˜í”„ë¡œ í™•ì¸ ë° ìƒì„¸ ë¶„ì„"""
        import matplotlib
        matplotlib.use('Agg')
        import matplotlib.pyplot as plt
        
        img = cv2.imread(image_path)
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        _, binary = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY_INV)
        
        horizontal_projection = np.sum(binary, axis=1)
        row_threshold = img.shape[1] * 255 * threshold_ratio
        
        # ê·¸ë˜í”„ ìƒì„±
        plt.figure(figsize=(15, 10))
        plt.subplot(2, 1, 1)
        plt.plot(horizontal_projection, linewidth=1)
        plt.axhline(y=row_threshold, color='r', linestyle='--', label=f'Threshold: {row_threshold:.1f}')
        plt.title(f'Horizontal Projection Analysis (Threshold Ratio: {threshold_ratio})')
        plt.xlabel('Row Index')
        plt.ylabel('Pixel Sum')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # íƒì§€ëœ ë¶„í• ì„ ë“¤ í‘œì‹œ
        detected_lines = np.where(horizontal_projection > row_threshold)[0]
        if len(detected_lines) > 0:
            plt.scatter(detected_lines, horizontal_projection[detected_lines], 
                    color='red', s=20, alpha=0.7, label='Detected Lines')
        
        # ìƒìœ„ í”¼í¬ë“¤ ë¶„ì„
        top_n = 10
        top_indices = np.argsort(horizontal_projection)[-top_n:][::-1]
        
        plt.subplot(2, 1, 2)
        plt.bar(range(top_n), horizontal_projection[top_indices])
        plt.axhline(y=row_threshold, color='r', linestyle='--', label=f'Threshold: {row_threshold:.1f}')
        plt.title(f'Top {top_n} Peaks Analysis')
        plt.xlabel('Peak Rank')
        plt.ylabel('Pixel Sum')
        plt.xticks(range(top_n), [f'Row {idx}' for idx in top_indices], rotation=45)
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        # íŒŒì¼ ì €ì¥
        output_path = image_path.replace('.jpg', '_projection_analysis.png').replace('.pdf', '_projection_analysis.png')
        plt.savefig(output_path, dpi=150, bbox_inches='tight')
        plt.close()
        
        # ìƒì„¸ ë¶„ì„ ê²°ê³¼ ì¶œë ¥
        print("="*60)
        print(f"ğŸ“Š Horizontal Projection Analysis Results")
        print("="*60)
        print(f"ì´ë¯¸ì§€ í¬ê¸°: {img.shape[1]} x {img.shape[0]}")
        print(f"ì„ê³„ê°’ ë¹„ìœ¨: {threshold_ratio}")
        print(f"ê³„ì‚°ëœ ì„ê³„ê°’: {row_threshold:.1f}")
        print(f"ìµœëŒ€ í”½ì…€ í•©ê³„: {np.max(horizontal_projection):,.0f}")
        print(f"í‰ê·  í”½ì…€ í•©ê³„: {np.mean(horizontal_projection):,.0f}")
        
        print(f"\nğŸ¯ íƒì§€ëœ ë¶„í• ì„  ì •ë³´:")
        print(f"ì´ íƒì§€ëœ í–‰ ìˆ˜: {len(detected_lines)}")
        
        if len(detected_lines) > 0:
            # ì—°ì†ëœ í–‰ë“¤ì„ ê·¸ë£¹í™”
            groups = []
            current_group = [detected_lines[0]]
            
            for i in range(1, len(detected_lines)):
                if detected_lines[i] - detected_lines[i-1] <= 5:  # 5í”½ì…€ ì´ë‚´ ì—°ì†
                    current_group.append(detected_lines[i])
                else:
                    groups.append(current_group)
                    current_group = [detected_lines[i]]
            groups.append(current_group)
            
            print(f"ë¶„í•  ê·¸ë£¹ ìˆ˜: {len(groups)}")
            for i, group in enumerate(groups):
                start_row = group[0]
                end_row = group[-1]
                group_height = len(group)
                avg_intensity = np.mean(horizontal_projection[group])
                print(f"  ê·¸ë£¹ {i+1}: Row {start_row:4d}~{end_row:4d} (ë†’ì´: {group_height:2d}px, í‰ê· ê°•ë„: {avg_intensity:,.0f})")
        
        print(f"\nğŸ“ˆ ìƒìœ„ 10ê°œ í”¼í¬ ë¶„ì„:")
        for i, idx in enumerate(top_indices):
            above_threshold = "âœ…" if horizontal_projection[idx] > row_threshold else "âŒ"
            print(f"  {i+1:2d}. Row {idx:4d}: {horizontal_projection[idx]:8,.0f} {above_threshold}")
        
        # ë¶„í•  ì˜ˆìƒ ê²°ê³¼
        if len(detected_lines) > 0:
            # ì‹¤ì œ ë¶„í•  ì§€ì  ê³„ì‚°
            split_points = [0]
            for group in groups:
                center = (group[0] + group[-1]) // 2
                split_points.append(center)
            split_points.append(img.shape[0])
            
            print(f"\nâœ‚ï¸  ì˜ˆìƒ ë¶„í•  ê²°ê³¼:")
            print(f"ì´ ë¶„í•  ì˜ì—­ ìˆ˜: {len(split_points)-1}")
            for i in range(len(split_points)-1):
                height = split_points[i+1] - split_points[i]
                print(f"  ì˜ì—­ {i+1}: Row {split_points[i]:4d}~{split_points[i+1]:4d} (ë†’ì´: {height:3d}px)")
        
        print(f"\nğŸ’¾ ê·¸ë˜í”„ ì €ì¥ ìœ„ì¹˜: {output_path}")
        print("="*60)
        
        return {
            'detected_lines': detected_lines,
            'groups': groups if len(detected_lines) > 0 else [],
            'threshold': row_threshold,
            'max_value': np.max(horizontal_projection),
            'top_peaks': [(idx, horizontal_projection[idx]) for idx in top_indices]
        }


    @staticmethod
    def debug_thickness_filtering(image_path, threshold_ratio=0.35, proximity_distance=10, min_group_thickness=5):
        """ë‘ê»˜ í•„í„°ë§ ê³¼ì •ì„ ìƒì„¸íˆ ë¶„ì„"""
        img = cv2.imread(image_path)
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        _, binary = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY_INV)

        horizontal_projection = np.sum(binary, axis=1)
        row_threshold = img.shape[1] * 255 * threshold_ratio
        detected_lines = np.where(horizontal_projection > row_threshold)[0]

        # ê·¸ë£¹í™”
        groups = []
        current_group = [detected_lines[0]]

        for i in range(1, len(detected_lines)):
            if detected_lines[i] - detected_lines[i-1] <= proximity_distance:
                current_group.append(detected_lines[i])
            else:
                groups.append(current_group)
                current_group = [detected_lines[i]]
        groups.append(current_group)

        print("="*60)
        print("ğŸ” ë‘ê»˜ í•„í„°ë§ ë¶„ì„")
        print("="*60)
        print(f"ìµœì†Œ ë‘ê»˜ ê¸°ì¤€: {min_group_thickness}px")
        
        valid_groups = []
        rejected_groups = []
        
        for i, group in enumerate(groups):
            thickness = len(group)
            start_row = min(group)
            end_row = max(group)
            
            if thickness >= min_group_thickness:
                valid_groups.append((start_row, thickness))
                print(f"âœ… ê·¸ë£¹ {i+1}: Row {start_row}~{end_row} (ë‘ê»˜: {thickness}px) â†’ ë¶„í• ì : {start_row}")
            else:
                rejected_groups.append((start_row, thickness))
                print(f"âŒ ê·¸ë£¹ {i+1}: Row {start_row}~{end_row} (ë‘ê»˜: {thickness}px) â†’ ì œì™¸ë¨ (ë„ˆë¬´ ì–‡ìŒ)")
        
        print(f"\nğŸ“Š í•„í„°ë§ ê²°ê³¼:")
        print(f"ìœ íš¨í•œ ê·¸ë£¹: {len(valid_groups)}ê°œ")
        print(f"ì œì™¸ëœ ê·¸ë£¹: {len(rejected_groups)}ê°œ")
        
        if valid_groups:
            print(f"ë¶„í• ì ë“¤: {[row for row, _ in valid_groups]}")
        
        return valid_groups, rejected_groups

    @staticmethod
    def split_image_by_horizontal_lines(image_path, base_serial, start_index, 
                                        threshold_ratio=0.4, proximity_distance=10, 
                                        min_row_height=10, min_group_thickness=5, dept=None, model=None):
        """
        ì´ë¯¸ì§€ì—ì„œ ìˆ˜í‰ì„ ì„ ê¸°ì¤€ìœ¼ë¡œ ì´ë¯¸ì§€ë¥¼ ë¶„í• í•©ë‹ˆë‹¤.
        
        :param image_path: ì´ë¯¸ì§€ë¥¼ ë¶„í• í•  ì´ë¯¸ì§€ íŒŒì¼ì˜ ê²½ë¡œ
        :param threshold: ìˆ˜í‰ì„  ê²€ì¶œì„ ìœ„í•œ ì„ê³„ê°’
        :param min_row_height: ìµœì†Œ í–‰ ë†’ì´
        :return: ë¶„í• ëœ ì´ë¯¸ì§€ë“¤ì˜ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        """
        # ì´ë¯¸ì§€ ë¡œë“œ
        img = cv2.imread(image_path, cv2.IMREAD_COLOR)
        if img is None:
            print(f"ì´ë¯¸ì§€ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")
            return []
        
        if base_serial is None:
            base_serial = os.path.basename(image_path).split('.')[0]
        
        if start_index is None:
            start_index = 0

        # ImageProcessor.debug_thickness_filtering(image_path, threshold_ratio=0.35, proximity_distance=10, min_group_thickness=min_row_height)
        # ImageProcessor.debug_clustering(image_path)
        # ImageProcessor.debug_horizontal_projection(image_path)
        """
        ì„ê³„ê°’ì„ ë„˜ëŠ” í”½ì…€ í•©ê³„ê°€ ë°€ì§‘ëœ êµ¬ê°„ì„ ê·¸ë£¹í™”í•˜ê³ ,
        ê·¸ë£¹ ë‘ê»˜ê°€ min_group_thickness ì´ìƒì¸ ê²½ìš°ì—ë§Œ ë¶„í• ì ìœ¼ë¡œ ì‚¬ìš©
        """
        img = cv2.imread(image_path)
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        _, binary = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY_INV)

        horizontal_projection = np.sum(binary, axis=1)
        row_threshold = img.shape[1] * 255 * threshold_ratio  # ìˆ˜ì •: img.shape[1]

        detected_lines = np.where(horizontal_projection > row_threshold)[0]  # ìˆ˜ì •: [0] ì¶”ê°€

        # ì¢Œìš° ë§ˆì§„ ì°¾ê¸° (ìˆ˜ì§ íˆ¬ì˜ ê³„ì‚°)
        vertical_projection = np.sum(binary, axis=0)
        left_margin = 0
        right_margin = img.shape[1] - 1

        # ì™¼ìª½ ë§ˆì§„ ì°¾ê¸° (ì™¼ìª½ì—ì„œ ì˜¤ë¥¸ìª½ìœ¼ë¡œ íƒìƒ‰)
        for i, value in enumerate(vertical_projection):
            if value > 0:  # ê²€ì • í”½ì…€ì´ ìˆëŠ” ê²½ìš°
                left_margin = i
                break

        # ì˜¤ë¥¸ìª½ ë§ˆì§„ ì°¾ê¸° (ì˜¤ë¥¸ìª½ì—ì„œ ì™¼ìª½ìœ¼ë¡œ íƒìƒ‰)
        for i in range(img.shape[1] - 1, -1, -1):
            if vertical_projection[i] > 0:  # ê²€ì • í”½ì…€ì´ ìˆëŠ” ê²½ìš°
                right_margin = i
                break

        print(f"ì¢Œìš° ë§ˆì§„: left_margin={left_margin}, right_margin={right_margin}")
        margin_width = right_margin - left_margin
        min_split_thickness = max(min_group_thickness, int(margin_width * 0.02))  # ë§ˆì§„ 
        print(f"ë§ˆì§„ í­: {margin_width}px, ìµœì†Œ ë¶„í•  ë‘ê»˜: {min_split_thickness}px")
        if len(detected_lines) == 0 or (dept in ['3186', 'JUXTA'] and (start_index == 0 and model != 'VJ77')):
            
            # ì „ì²´ ì´ë¯¸ì§€ë¥¼ ì¢Œìš° ë§ˆì§„ìœ¼ë¡œë§Œ í¬ë¡­
            if left_margin < right_margin:
                cropped = img[0:img.shape[0], left_margin:right_margin + 1]  # ìˆ˜ì •: img.shape[0]
                
                if cropped.size > 0:
                    output_filename = f"{base_serial}_{start_index}.png"
                    base_directory = os.path.dirname(os.path.dirname(image_path))
                    process_folder = os.path.join(base_directory, 'Process', base_serial)
                    os.makedirs(process_folder, exist_ok=True)
                    output_path = os.path.join(process_folder, output_filename)

                    cv2.imwrite(output_path, cropped)
                    print(f"ì €ì¥ë¨: {output_filename} (ì „ì²´ ì´ë¯¸ì§€, ì¢Œìš° ë§ˆì§„ ì ìš©, í¬ê¸°: {cropped.shape})")
                    return [output_path]
                else:
                    print("âŒ í¬ë¡­ëœ ì´ë¯¸ì§€ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
                    return [image_path]
            else:
                print("âŒ ìœ íš¨í•˜ì§€ ì•Šì€ ì¢Œìš° ë§ˆì§„ì…ë‹ˆë‹¤.")
                return [image_path]

        print(f"íƒì§€ëœ ì›ë³¸ í–‰ë“¤: {detected_lines}")

        # ë°€ì§‘ëœ í–‰ë“¤ì„ ê·¸ë£¹í™”
        groups = []
        current_group = [detected_lines[0]]  # ìˆ˜ì •: detected_lines[0]

        for i in range(1, len(detected_lines)):
            if detected_lines[i] - detected_lines[i-1] <= proximity_distance:
                current_group.append(detected_lines[i])
            else:
                groups.append(current_group)
                current_group = [detected_lines[i]]
        groups.append(current_group)

        print(f"ê·¸ë£¹í™” ê²°ê³¼:")
        for i, group in enumerate(groups):
            thickness = len(group)
            print(f"  ê·¸ë£¹ {i+1}: Row {group[0]}~{group[-1]} (ë‘ê»˜: {thickness}px)")

        split_rows = []
        for group in groups:
            group_thickness = len(group)
            if group_thickness >= 20 and group_thickness <= 40:
                # ì¶”ê°€ ê²€ì‚¬: í•´ë‹¹ ê·¸ë£¹ ì˜ì—­ì˜ ì¢Œìš° ë§ˆì§„ ê³„ì‚°
                group_start = min(group)
                group_end = max(group)
                
                # ê·¸ë£¹ ì˜ì—­ì˜ ìˆ˜ì§ íˆ¬ì˜ ê³„ì‚°
                group_region = binary[group_start:group_end+1, :]
                group_vertical_projection = np.sum(group_region, axis=0)
                
                # ê·¸ë£¹ì˜ ì¢Œìš° ë§ˆì§„ ì°¾ê¸°
                group_left_margin = 0
                group_right_margin = img.shape[1] - 1
                
                # ê·¸ë£¹ì˜ ì™¼ìª½ ë§ˆì§„
                for i, value in enumerate(group_vertical_projection):
                    if value > 0:
                        group_left_margin = i
                        break
                
                # ê·¸ë£¹ì˜ ì˜¤ë¥¸ìª½ ë§ˆì§„
                for i in range(img.shape[1] - 1, -1, -1):
                    if group_vertical_projection[i] > 0:
                        group_right_margin = i
                        break
                
                # ê·¸ë£¹ì˜ í­ ê³„ì‚°
                group_margin_width = group_right_margin - group_left_margin
                
                # ì „ì²´ í­ê³¼ ë¹„êµí•˜ì—¬ ìµœì¢… ê²°ì •
                if group_margin_width >= margin_width * 0.8:  # ì „ì²´ í­ì˜ 80% ì´ìƒ
                    front_row = min(group)
                    split_rows.append(front_row)
                    print(f"    âœ… ë¶„í• ì  ì¶”ê°€: {front_row} (ë‘ê»˜: {group_thickness}px, í­: {group_margin_width}px)")
                else:
                    print(f"    âŒ í­ ë¶€ì¡±: Row {group[0]}~{group[-1]} (í­: {group_margin_width}px < {margin_width * 0.8}px)")
            else:
                print(f"    âŒ ë„ˆë¬´ ì–‡ìŒ: Row {group[0]}~{group[-1]} (ë‘ê»˜: {group_thickness}px)")
        # ë¶„í• ì  ì„¤ì •: ì´ë¯¸ì§€ ì‹œì‘(0) + í•„í„°ë§ëœ ê·¸ë£¹ì˜ ì•ë¶€ë¶„ + ì´ë¯¸ì§€ ë
        split_points = [0] + split_rows + [img.shape[0]]
        split_points = sorted(list(set(split_points)))

        print(f"ìµœì¢… ë¶„í• ì ë“¤: {split_points}")
    
        # ì´ë¯¸ì§€ ë¶„í•  ë° ì €ì¥
        saved_files = []
        print(f"DEBUG: dept={dept}, model={model}, start_index={start_index}")
        for i in range(len(split_points) - 1):
            y_start = split_points[i]
            y_end = split_points[i + 1]

            if (dept in ['3186', 'JUXTA']) and (i ==1 or i == 2) and (model != 'VJ77'):
                # JUXTA ê³µì • ë‚´ì „ì••, ê¸°ëŠ¥ê²€ì‚¬ ì œì™¸
                print(f"Skipping segment {i} due to dept condition")
                continue
            elif (dept in ['3186', 'JUXTA']) and (i == 0 or i == 2) and (model == 'VJ77') and start_index == 0:
                # VJ77 ëª¨ë¸ì˜ ì²« ë²ˆì§¸ ì„¸ê·¸ë¨¼íŠ¸ëŠ” ì œì™¸
                print(f"Skipping segment {i} due to model condition")
                continue

            if y_end - y_start > min_row_height and left_margin < right_margin:
                # ì¢Œìš° ë§ˆì§„ì„ ì ìš©í•œ í¬ë¡­
                cropped = img[y_start:y_end, left_margin:right_margin + 1]
                
                if cropped.size > 0:
                    if dept in ['3186', 'JUXTA'] and i>=3 and model != 'VJ77':
                        file_index = start_index + i - 2
                    elif dept in ['3186', 'JUXTA'] and i==1 and model == 'VJ77' and start_index == 0:
                        file_index = start_index + i - 1
                    elif dept == '3188':
                        # 3188 ê³µì •ì€ ìˆœì°¨ì ìœ¼ë¡œ ì €ì¥
                        file_index = start_index + i
                    else:
                        file_index = start_index + i
                    output_filename = f"{base_serial}_{file_index}.png"
                    base_directory = os.path.dirname(os.path.dirname(image_path))
                    process_folder = os.path.join(base_directory,'Process', base_serial)
                    os.makedirs(process_folder, exist_ok=True)
                    output_path = os.path.join(process_folder, output_filename)

                    cv2.imwrite(output_path, cropped)
                    saved_files.append(output_path)
                    
                    print(f"ì €ì¥ë¨: {output_filename} (Row {y_start}~{y_end}, Col {left_margin}~{right_margin}, í¬ê¸°: {cropped.shape})")
                else:
                    print(f"ë¹ˆ ì´ë¯¸ì§€ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤: {output_filename}")
            else:
                print(f"ìœ íš¨í•˜ì§€ ì•Šì€ ì˜ì—­ì„ ê±´ë„ˆëœë‹ˆë‹¤: Row {y_start}~{y_end}")
                
        return saved_files

    @staticmethod
    def merge_checksheet_images_uta(image_paths, output_path, target_width=800):
        """
        ëª¨ë“  ì²´í¬ì‹œíŠ¸ ì´ë¯¸ì§€ë¥¼ í•˜ë‚˜ì˜ ì´ë¯¸ì§€ë¡œ ì„¸ë¡œë¡œ í•©ì¹©ë‹ˆë‹¤.
        
        :param image_paths: í•©ì¹  ì´ë¯¸ì§€ë“¤ì˜ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        :param output_path: í•©ì³ì§„ ì´ë¯¸ì§€ë¥¼ ì €ì¥í•  ê²½ë¡œ
        :param target_width: ëª¨ë“  ì´ë¯¸ì§€ì˜ ë™ì¼í•œ ë„ˆë¹„
        """
        images = []
        # ì´ë¯¸ì§€ ë¶ˆëŸ¬ì˜¤ê¸° ë° í¬ê¸° ì¡°ì •
        for path in image_paths:
            try:
                img = Image.open(path)
                # ë¹„ìœ¨ì„ ìœ ì§€í•˜ë©° ë†’ë¹„ë¥¼ target_widthë¡œ ì¡°ì •
                aspect_ratio = target_width / img.width
                new_height = int(img.height * aspect_ratio)
                img = img.resize((target_width, new_height), Image.LANCZOS)
                images.append(img)
            except Exception as e:
                print(f"ì´ë¯¸ì§€ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {path}, ì˜¤ë¥˜: {e}")

        if not images:
            print("í•©ì¹  ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        # ëª¨ë“  ì´ë¯¸ì§€ì˜ ì´ ë„ˆì´ ê³„ì‚°
        total_height = sum(img.height for img in images)
        # í•©ì³ì§ˆ ì´ë¯¸ì§€ì˜ í¬ê¸° ì„¤ì •
        merged_image = Image.new('RGB', (target_width, total_height))

        # ì´ë¯¸ì§€ ìˆœì„œëŒ€ë¡œ í•©ì¹˜ê¸°
        current_y = 0
        for img in images:
            merged_image.paste(img, (0, current_y))
            current_y += img.height

        # í•©ì³ì§„ ì´ë¯¸ì§€ ì €ì¥
        merged_image.save(output_path)
        print(f"ì²´í¬ì‹œíŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ í•©ì³ì¡ŒìŠµë‹ˆë‹¤: {output_path}")

    @staticmethod
    def merge_checksheet_images_juxta(image_paths, output_path, target_width=800):
        """
        - ì²« ë²ˆì§¸(ì™¼ìª½) ì´ë¯¸ì§€ëŠ” ì›ë³¸ í¬ê¸° ê·¸ëŒ€ë¡œ ì‚¬ìš©.
        - ì˜¤ë¥¸ìª½ ì´ë¯¸ì§€ëŠ” ì—¬ëŸ¬ ì¥(ê³µì • 07,10,11 ë“±)ì„ ì„¸ë¡œë¡œ ì´ì–´ë¶™ì¸ ë’¤,
        'ì™¼ìª½ ì´ë¯¸ì§€ì˜ ë†’ì´'ì— ë§ì¶° ì¶•ì†Œ(í˜¹ì€ í™•ëŒ€)í•œ ë‹¤ìŒ, ì¢Œìš°ë¡œ í•©ì¹œë‹¤.
        - ê²°ê³¼ì ìœ¼ë¡œ, "ì™¼ìª½ ì´ë¯¸ì§€ëŠ” ì›ë³¸ ê·¸ëŒ€ë¡œ, ì˜¤ë¥¸ìª½ ì´ë¯¸ì§€ëŠ” ì„¸ë¡œ ê¸¸ì´ë§Œ ì™¼ìª½ì— ë§ì¶¤."
        """

        if not image_paths:
            print("í•©ì¹  ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        # 1) ë§¨ ì• ì´ë¯¸ì§€ = 'ì™¼ìª½' ê¸°ì¤€ ì´ë¯¸ì§€
        left_path = image_paths[0]
        right_paths = image_paths[1:]  # ë‚˜ë¨¸ì§€(ì˜¤ë¥¸ìª½ì— ë¶™ì¼ ì´ë¯¸ì§€ë“¤)

        # (A) ì™¼ìª½ ì´ë¯¸ì§€ ë¡œë“œ
        try:
            img_left = cv2.imread(left_path, cv2.IMREAD_COLOR)  # shape: (h, w, 3), BGR
            if img_left is None:
                print(f"ì™¼ìª½ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {left_path}")
                return
        except Exception as e:
            print(f"ì™¼ìª½ ì´ë¯¸ì§€ ë¡œë“œ ì˜¤ë¥˜: {left_path}, {e}")
            return

        # (B) ì˜¤ë¥¸ìª½ ì´ë¯¸ì§€ ë¡œë“œ
        right_images = []
        for path in right_paths:
            try:
                img_r = cv2.imread(path, cv2.IMREAD_COLOR)
                if img_r is not None:
                    right_images.append(img_r)
                else:
                    print(f"ì˜¤ë¥¸ìª½ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {path}")
            except Exception as e:
                print(f"ì˜¤ë¥¸ìª½ ì´ë¯¸ì§€ ë¡œë“œ ì˜¤ë¥˜: {path}, {e}")

        # ì˜¤ë¥¸ìª½ì— í•©ì¹  ì´ë¯¸ì§€ê°€ ì—†ë‹¤ë©´, ì™¼ìª½ë§Œ ì €ì¥
        if not right_images:
            print("ì˜¤ë¥¸ìª½ì— í•©ì¹  ì´ë¯¸ì§€ê°€ ì—†ì–´, ì™¼ìª½ ë‹¨ì¼ ì´ë¯¸ì§€ë§Œ ì €ì¥í•©ë‹ˆë‹¤.")
            cv2.imwrite(output_path, img_left)
            print(f"ë‹¨ì¼ ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: {output_path}")
            return

        widths = [img.shape[1] for img in right_images]
        max_width = max(widths)

        resized_right_list = []
        for img in right_images:
            h, w, c = img.shape
            if w != max_width:
                scale_factor = max_width / float(w)
                new_h = int(h * scale_factor)
                # ì¶•ì†Œ/í™•ëŒ€ì— ë”°ë¥¸ ë³´ê°„ ì„¤ì •
                if new_h > h:  
                    img_rz = cv2.resize(img, (max_width, new_h), interpolation=cv2.INTER_CUBIC)
                else:
                    img_rz = cv2.resize(img, (max_width, new_h), interpolation=cv2.INTER_AREA)
                resized_right_list.append(img_rz)
            else:
                resized_right_list.append(img)

        # ì„¸ë¡œ ë°©í–¥ìœ¼ë¡œ ìŒ“ê¸°
        big_right_raw = np.concatenate(resized_right_list, axis=0)

        # (D) ì˜¤ë¥¸ìª½ ì „ì²´ë¥¼ 'ì™¼ìª½ ì´ë¯¸ì§€ ë†’ì´'ì— ë§ì¶° ë¦¬ì‚¬ì´ì¦ˆ
        h_left, w_left, _ = img_left.shape
        h_right_raw, w_right_raw, _ = big_right_raw.shape

        if h_right_raw != h_left:
            scale_r = h_left / float(h_right_raw)
            new_w_right = int(w_right_raw * scale_r)
            # ì¶•ì†Œ vs í™•ëŒ€ì— ë”°ë¼ ë³´ê°„ ë‹¤ë¥´ê²Œ
            if h_left < h_right_raw:
                big_right_resized = cv2.resize(big_right_raw, (new_w_right, h_left), interpolation=cv2.INTER_AREA)
            else:
                big_right_resized = cv2.resize(big_right_raw, (new_w_right, h_left), interpolation=cv2.INTER_CUBIC)
        else:
            big_right_resized = big_right_raw

        # (E) ì´ì œ ì¢Œìš°ë¡œ í•©ì¹˜ê¸°
        merged = np.concatenate((img_left, big_right_resized), axis=1)

        # (F) ì €ì¥
        #   - JPGë¡œ ì €ì¥ ì‹œ í’ˆì§ˆ ì„¤ì • ê°€ëŠ¥
        #   - PNGë¡œ ì €ì¥ ì‹œ ë¬´ì†ì‹¤
        ext = os.path.splitext(output_path)[1].lower()
        if ext in [".jpg", ".jpeg"]:
            cv2.imwrite(output_path, merged, [cv2.IMWRITE_JPEG_QUALITY, 95])
        else:
            cv2.imwrite(output_path, merged)

        print(f"[JUXTA] ì²´í¬ì‹œíŠ¸ ë³‘í•© ì™„ë£Œ: {output_path}")

    @staticmethod
    def merge_checksheet_images_newsc(left_images, right_image, output_path):
        """
        NEW SC/3188 ì „ìš© ë³‘í•© í•¨ìˆ˜
        - ì™¼ìª½: ì—¬ëŸ¬ ì´ë¯¸ì§€ë¥¼ ì„¸ë¡œë¡œ í•©ì¹¨ (0.png, 06.png, 2.png)
        - ì˜¤ë¥¸ìª½: ë‹¨ì¼ ì´ë¯¸ì§€ (09.png)
        - ìµœì¢…: ì¢Œìš°ë¡œ ë°°ì¹˜
        """
        if not left_images or not right_image:
            print("ë³‘í•©í•  ì´ë¯¸ì§€ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
            return
        
        try:
            # ì™¼ìª½ ì´ë¯¸ì§€ë“¤ ë¡œë“œ ë° ì„¸ë¡œ ë³‘í•©
            left_cv_images = []
            for path in left_images:
                img = cv2.imread(path, cv2.IMREAD_COLOR)
                if img is not None:
                    left_cv_images.append(img)
                else:
                    print(f"ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {path}")
            
            if not left_cv_images:
                print("ì™¼ìª½ ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            # ì™¼ìª½ ì´ë¯¸ì§€ë“¤ ë„ˆë¹„ í†µì¼
            widths = [img.shape[1] for img in left_cv_images]
            max_width = max(widths)
            
            resized_left_list = []
            for img in left_cv_images:
                h, w, c = img.shape
                if w != max_width:
                    scale_factor = max_width / float(w)
                    new_h = int(h * scale_factor)
                    if new_h > h:
                        img_rz = cv2.resize(img, (max_width, new_h), interpolation=cv2.INTER_CUBIC)
                    else:
                        img_rz = cv2.resize(img, (max_width, new_h), interpolation=cv2.INTER_AREA)
                    resized_left_list.append(img_rz)
                else:
                    resized_left_list.append(img)
            
            # ì™¼ìª½ ì´ë¯¸ì§€ë“¤ì„ ì„¸ë¡œë¡œ ë³‘í•©
            merged_left = np.concatenate(resized_left_list, axis=0)
            
            # ì˜¤ë¥¸ìª½ ì´ë¯¸ì§€ ë¡œë“œ
            img_right = cv2.imread(right_image, cv2.IMREAD_COLOR)
            if img_right is None:
                print(f"ì˜¤ë¥¸ìª½ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {right_image}")
                return
            
            # ì˜¤ë¥¸ìª½ ì´ë¯¸ì§€ë¥¼ ì™¼ìª½ ë³‘í•© ì´ë¯¸ì§€ì˜ ë†’ì´ì— ë§ì¶° ì¡°ì •
            h_left, w_left, _ = merged_left.shape
            h_right, w_right, _ = img_right.shape
            
            if h_right != h_left:
                scale_r = h_left / float(h_right)
                new_w_right = int(w_right * scale_r)
                if h_left < h_right:
                    img_right_resized = cv2.resize(img_right, (new_w_right, h_left), interpolation=cv2.INTER_AREA)
                else:
                    img_right_resized = cv2.resize(img_right, (new_w_right, h_left), interpolation=cv2.INTER_CUBIC)
            else:
                img_right_resized = img_right
            
            # ì¢Œìš°ë¡œ ë³‘í•©
            merged = np.concatenate((merged_left, img_right_resized), axis=1)
            
            # ì €ì¥
            ext = os.path.splitext(output_path)[1].lower()
            if ext in [".jpg", ".jpeg"]:
                cv2.imwrite(output_path, merged, [cv2.IMWRITE_JPEG_QUALITY, 95])
            else:
                cv2.imwrite(output_path, merged)
            
            print(f"[NEW SC] ì²´í¬ì‹œíŠ¸ ë³‘í•© ì™„ë£Œ: {output_path}")
            
        except Exception as e:
            print(f"[NEW SC] ë³‘í•© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    @staticmethod
    def convert_pdf_to_process_images(dept, process, serial, base_folder, model=None, base_folder_ori=None):
        """
        UTA:
        - ê¸°ì¡´ëŒ€ë¡œ í•œ PDF â†’ ì „ë¶€ split
        JUXTA:
        - PDF 2ê°œ ì¡´ì¬, setê³µì •=04(serial_0.pdf), ë‚˜ë¨¸ì§€ê³µì •(serial_1.pdf)
        - serial_0.pdf ê·¸ëŒ€ë¡œ ì¶œë ¥
        - serial_1.pdf â†’ split_image_by_horizontal_lines
        NEW SC:
        - serial_0.pdf â†’ split, 1ë²ˆí•­ëª©ë§Œ ì €ì¥
        - serial_1.pdf â†’ ì›ë³¸ ê·¸ëŒ€ë¡œ ì‚¬ìš©
        """
        if dept in ['3165', 'UTA']:
            # ë¨¼ì € PNG íŒŒì¼ì´ ì´ë¯¸ ìˆëŠ”ì§€ í™•ì¸
            png_path = os.path.join(base_folder_ori, dept, 'Master', f"{serial}.png")
            pdf_path = os.path.join(base_folder_ori, dept, 'Master', f"{serial}.pdf")
            
            if os.path.exists(png_path):
                # PNG íŒŒì¼ì´ ì´ë¯¸ ìˆìœ¼ë©´ ì§ì ‘ ì‚¬ìš©
                images = [Image.open(png_path)]
            elif os.path.exists(pdf_path):
                # PDF íŒŒì¼ë§Œ ìˆìœ¼ë©´ ë³€í™˜
                images = convert_from_path(pdf_path, dpi=150)
            else:
                raise FileNotFoundError(f"PNG ë˜ëŠ” PDF íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {serial}")

            # ê²°ê³¼ ì €ì¥ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
            saved_paths = []

            # 1) UTA ì²˜ë¦¬
            
            # UTAëŠ” ní˜ì´ì§€ ëª¨ë‘ split
            page_index = 0
            for pil_img in images:
                # í˜ì´ì§€ ì„ì‹œ ì €ì¥
                page_jpg_path = os.path.join(base_folder, dept, 'Master', f"{serial}.png")
                pil_img.save(page_jpg_path, 'png')
                # split
                splitted = ImageProcessor.split_image_by_horizontal_lines(page_jpg_path, serial, page_index, dept=dept)
                saved_paths.extend(splitted)
                page_index += 1

            return saved_paths

        # 2) JUXTA ì²˜ë¦¬
        elif dept in ['3186', 'JUXTA']:
            saved_paths = []
        
            # ê³µì • 04: serial_0.pdf ì‚¬ìš© (splití•˜ì§€ ì•ŠìŒ)
            pdf_path = os.path.join(base_folder_ori, dept, 'Master', f"{serial}_0.pdf")
            if not os.path.exists(pdf_path):
                raise FileNotFoundError(f"PDFê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {pdf_path}")
            # PDF â†’ PIL ì´ë¯¸ì§€ ë³€í™˜
            images = convert_from_path(pdf_path, dpi=180)
            
            # ì²« ë²ˆì§¸ í˜ì´ì§€ë§Œ ì‚¬ìš©í•˜ê³  splití•˜ì§€ ì•ŠìŒ
            if images:
                temp_jpg_path =  os.path.join(base_folder, dept, 'Master', f"{serial}_0.png")
                # ì´ë¯¸ì§€ ì €ì¥ (splití•˜ì§€ ì•Šê³  ê·¸ëŒ€ë¡œ)
                images[0].save(temp_jpg_path, 'PNG')
                splitted = ImageProcessor.split_image_by_horizontal_lines(
                    temp_jpg_path,
                    base_serial=serial,
                    start_index=0,
                    dept=dept,
                    model=model)

            pdf_path = os.path.join(base_folder_ori, dept, 'Master', f"{serial}_1.pdf")
            if not os.path.exists(pdf_path):
                raise FileNotFoundError(f"PDFê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {pdf_path}")
            # PDF â†’ PIL ì´ë¯¸ì§€ ë³€í™˜
            images = convert_from_path(pdf_path, dpi=180)
            # ì´ë¯¸ì§€ë¥¼ jpgë¡œ ì„ì‹œ ì €ì¥í•œ í›„ split ì ìš©
            if images:
                temp_jpg_path = os.path.join(base_folder, dept, 'Master', f"{serial}_1.png")
                images[0].save(temp_jpg_path, 'PNG')
                # split ì ìš© (ì¸ë±ìŠ¤ 1ë¶€í„° ì‹œì‘)
                splitted = ImageProcessor.split_image_by_horizontal_lines(
                    temp_jpg_path,
                    base_serial=serial,
                    start_index=1,
                    dept=dept,
                    model=model
                )
                saved_paths.extend(splitted)

            return saved_paths
        # 2) NEWSC ì²˜ë¦¬
        elif dept in ['3188', 'NEW SC']:
            saved_paths = []
        
            # ì²« ë²ˆì§¸ PDF ì²˜ë¦¬ - ë¶„í• 
            pdf_path = os.path.join(base_folder_ori, dept, 'Master', f"{serial}_0.pdf")
            if not os.path.exists(pdf_path):
                raise FileNotFoundError(f"PDFê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {pdf_path}")
            # PDF â†’ PIL ì´ë¯¸ì§€ ë³€í™˜
            images = convert_from_path(pdf_path, dpi=180)
            if images:
                temp_jpg_path =  os.path.join(base_folder, dept, 'Master', f"{serial}_0.png")
                # ì´ë¯¸ì§€ ì €ì¥
                images[0].save(temp_jpg_path, 'PNG')
                # ì²« ë²ˆì§¸ PDFëŠ” ë¶„í• í•˜ì—¬ 0, 1, 2.png ë“±ìœ¼ë¡œ ì €ì¥
                splitted = ImageProcessor.split_image_by_horizontal_lines(
                    temp_jpg_path,
                    base_serial=serial,
                    start_index=0,
                    dept=dept,
                    model=model)
                saved_paths.extend(splitted)

            # ë‘ ë²ˆì§¸ PDF ì²˜ë¦¬ - ë¶„í• í•˜ì§€ ì•Šê³  ê·¸ëŒ€ë¡œ ì‚¬ìš©
            pdf_path = os.path.join(base_folder_ori, dept, 'Master', f"{serial}_1.pdf")
            if not os.path.exists(pdf_path):
                raise FileNotFoundError(f"PDFê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {pdf_path}")
            # PDF â†’ PIL ì´ë¯¸ì§€ ë³€í™˜
            images = convert_from_path(pdf_path, dpi=180)
            if images:
                temp_jpg_path = os.path.join(base_folder, dept, 'Master', f"{serial}_1.png")
                images[0].save(temp_jpg_path, 'PNG')
                # ì²« ë²ˆì§¸ PDFì˜ ë¶„í•  ê°œìˆ˜ë¥¼ íŒŒì•…í•˜ì—¬ ë‹¤ìŒ ë²ˆí˜¸ë¡œ ì €ì¥
                next_index = len(saved_paths)  # ì²« ë²ˆì§¸ PDFì—ì„œ ìƒì„±ëœ íŒŒì¼ ê°œìˆ˜
                # ë‘ ë²ˆì§¸ PDFëŠ” ë¶„í• í•˜ì§€ ì•Šê³  ê·¸ëŒ€ë¡œ ì‚¬ìš© (start_indexë¥¼ ë‹¤ìŒ ë²ˆí˜¸ë¡œ ì„¤ì •)
                splitted = ImageProcessor.split_image_by_horizontal_lines(
                    temp_jpg_path,
                    base_serial=serial,
                    start_index=next_index,  # ì²« ë²ˆì§¸ PDF ë¶„í•  ê°œìˆ˜ë§Œí¼ ì‹œì‘ ì¸ë±ìŠ¤ ì„¤ì •
                    dept=dept,
                    model=model
                )
                saved_paths.extend(splitted)

            return saved_paths

        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ë¶€ì„œì½”ë“œ: {dept}")

        
